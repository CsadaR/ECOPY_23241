{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de9d9737616514b8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Az osztály(oka)t mentsd a __src/linear_regression__ modul __LinearRegressions.py__ fájljába\n",
    "Használható modulok: _pathlib, pandas, typing, str, numpy_, valamint a _scipy.stats t_ és _f_ osztályai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 2;\n                var nbb_unformatted_code = \"from pandas import Series\\n%load_ext nb_black\\n%load_ext autoreload\\n%autoreload 2\";\n                var nbb_formatted_code = \"from pandas import Series\\n\\n%load_ext nb_black\\n%load_ext autoreload\\n%autoreload 2\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T10:12:33.689205200Z",
     "start_time": "2023-11-14T10:12:32.178114Z"
    }
   },
   "id": "7066ec7a2294843b"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfea6e648868022e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T10:12:33.735110800Z",
     "start_time": "2023-11-14T10:12:33.688113400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 3;\n                var nbb_unformatted_code = \"from pathlib import Path\\n\\nimport numpy as np\\nimport pandas as pd\";\n                var nbb_formatted_code = \"from pathlib import Path\\n\\nimport numpy as np\\nimport pandas as pd\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 4;\n                var nbb_unformatted_code = \"datalib = Path.cwd().parent.joinpath('data')\";\n                var nbb_formatted_code = \"datalib = Path.cwd().parent.joinpath(\\\"data\\\")\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datalib = Path.cwd().parent.joinpath('data')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T10:12:33.775111200Z",
     "start_time": "2023-11-14T10:12:33.733149300Z"
    }
   },
   "id": "b0b5dd4685315eda"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Adatelőkészítés (0 pont)\n",
    "1., Olvasd be a data mappa __sp500.parquet__ nevű fájlját egy DataFrame-be. A betöltéshez használt engine paramétere legyen <u>fastparquet</u>\n",
    "2., Olvasd be az __ff_factors.parquet__ fájlt egy DataFrame-be. A betöltéshez használt engine paramétere legyen <u>fastparquet</u>\n",
    "3., Kapcsold össze a két DataFrame-t egy új DataFrame-be. Az összekapcsolás módja, hogy a hozam adatokra balról kapcsoljuk rá a factor adatokat a __'Date' elsődleges kulcs__ alapján.\n",
    "4., Készíts egy új __'Excess Return'__ nevű oszlopot, ami a havi hozamok és a kockázat mentes hozam (RF) különbsége\n",
    "5., <u>Rendezd sorba dátum szerint az adatokat</u>, majd generálj egy új oszlopot (__'ex_ret_1'__), amely minden ticker ('Symbol') esetén 1-el eltolja az Excess Return értékeit olyan módon, hogy minden sorban szerepeljen a <u>következő időszaki Excess Return</u> érték. \n",
    "6., A meglévő adathalmazt írd felül olyan módon, hogy egyszer <u>törlöd az össze olyan sort</u>, amely az __'ex_ret_1' oszlopban hiányos__, majd ezt követően, törlöd az összes olyan sort, ami a __'HML' oszlopban hiányos__.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dad5a013c358987e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. feladat segítség\n",
    "![Joined data](../resources/weekly6/joined_data.jpg)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf54c6765186a23e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "5. feladat segítség\n",
    "![new column](../resources/weekly6/ex_ret_1.jpg)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6be746933376572"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4959bed9ce5596ed"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Modell összeállítás (7 pont)\n",
    "\n",
    "A meglévő adatokból válaszd ki a __Amazon részvényhez tartozó sorokat (AMZN)__ és töröld a tickereket tartalmazó oszlopot. <u>Amennyiben működött, önellenőrzésre használhatod a legutóbbi zárthelyin írt osztályt is.</u>\n",
    "\n",
    "7., Készíts egy új __LinearRegressionGLS__ elnevezésű osztályt. Definiáld benne a __\\_\\_init\\_\\___ nevű függvényt, amely bemenetként 2 DataFrame-t kap amelyeket ments le a left_hand_side és right_hand_side elnevezésű változókba. Az egyik DataFrame fogja tartalmazni a következő hónap többlet hozamait (__left_hand_side__), a másik a piaci hozamokat (Mkt-RF), az SMB és a HML értékeket (__right_hand_side__).\n",
    "\n",
    "8., Egésztsd ki az osztályt egy __fit__ metódussal, ami Feasible GLS elvű becslést hajt végre. Figyelj oda, hogy a regresszió futtatása során konstans (alfa / béta_0) is szerepeljen a predictor változók között, amely az első változó legyen. <u>__(numpy.linalg.lstsq() nem használható)__</u>\n",
    "\n",
    "9., Egészítsd ki az osztályt egy __get_params__ metódussal, ami visszaadja a becsült modell béta paramétereinek értékeit. A visszakapott pandas Series típusú adatban az oszlop neve legyen __Beta coefficients__. \n",
    "\n",
    "10., Egészítsd ki az osztályt egy __get_pvalues__ metódussal, ami visszaadja a becsült modell paraméterekhez tartozó p értékeket. A visszakapott pandas Series típusú adatban az oszlop neve legyen: __P-values for the corresponding coefficients__. A p értéket t-statisztika alapján számold ki. A p-érték kiszámításánál figyelj alkalmazd a <u>min(value, 1-value) * 2</u> képletet.\n",
    "\n",
    "11., Egészítsd ki az osztályt egy __get_wald_test_result__ metódussal, ami visszaadja a bemeneti restrikciós mátrix alapján számolt F és p értékeket. A visszatérési típus string legyen, a visszaadandó szöveg: __Wald: wald_value, p-value: p_value__, ahol az wald_value és p_value helyére 3 tizedesjegyre kerekítve (__:.3f__) add meg a hozzájuk tartozó értékeket. A függvény bemenete során feltételezzük, hogy r minden eleme 0, R-t listák listája formában adjuk át. A Wald statisztika p értékét az előző feladathoz hasonlóan számold ki, de figyelj, hogy a <u>teszt 1 oldalú</u>.\n",
    "\n",
    "12., Egészítse ki az osztályt egy __get_model_goodness_values__ metódussal, ami visszadja a centrált és a módosított R-négyzet értékeket. A visszatérési típus string legyen, a visszaadandó szöveg: __Centered R-squared: crs, Adjusted R-squared: ars__, ahol crs és ars helyére 3 tizedesjegyre kerekítve (__:.3f__) add meg a hozzájuk tartozó értékeket. <u>Ha a regresszorok számába eredetileg beleszámítottad a konstanst is, akkor a módosított R-négyzet számítás nevezőjében nincs szükség a __-1__-es tagra</u>."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1888d0ef54d4b2c3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "__Feasible GLS becslésének a menete__:\n",
    "1.) A bementeni adatok alapján OLS elven becsüld meg a változók együtthatóit.\n",
    "2.) Számold ki a hibatagokat\n",
    "3.) A hibatagoknak vedd a négyzetét\n",
    "4.) Becsülj egy új modellt, ahol a bal oldali változó a hibatag négyzetének logaritmusa, míg a jobboldali változók az eredeti jobb oldali változóid.\n",
    "5.) Számold ki a becsült értékeket (logaritmikus négyzetes hibákat) és vedd őket az e kitevőjeként.\n",
    "6.) A kapott vektornak vedd elemenként az inverzét és helyezd el egy diagonális mátrix főátlójában őket (np.diag). -> Az így kapott mátrix lesz a V inverz mátrix.\n",
    "7.) A V inverz mátrix felhasználásával becsüld meg a GLS regresszió paramétereit"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e27e69ded63aa7b3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    " def fit(self):\n",
    "\n",
    "        alfa_ols = sm.add_constant(self.right_hand_side)\n",
    "        beta_ols = self.left_hand_side\n",
    "        self._model_ols = sm.OLS(beta_ols, alfa_ols).fit()\n",
    "        self.beta_ols = self._model_ols.params\n",
    "        self.residuals = self.left_hand_side - self._model_ols.predict()\n",
    "        self.squared_residuals = np.log(np.square(self.residuals))\n",
    "        alfa_gls = sm.add_constant(self.right_hand_side)\n",
    "        alfa_gls['Squared_Residuals'] = np.log(self.squared_residuals)\n",
    "        self._model_gls = sm.OLS(alfa_gls,self.right_hand_side).fit()\n",
    "        self.beta_gls = self._model_gls.params\n",
    "        self.V_inverse = np.diag(1 / self.squared_residuals)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "679dfc102cbafe7c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e5be24b06cef2eb0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "    def get_pvalues(self):\n",
    "        dof = len(self.left_hand_side) - len(self.beta)\n",
    "        t_values = self.beta / np.sqrt(np.diag(self.cov_matrix))\n",
    "        p_values = 2 * (1 - t.cdf(np.abs(t_values), df=dof))\n",
    "        p_values = pd.Series(np.minimum(p_values, 2 * (1 - p_values)), name='P-values for the corresponding coefficients')\n",
    "        return p_values\n",
    "\n",
    "    def get_wald_test_result(self, R):\n",
    "        wald_value = float(np.dot(np.dot(R, self.beta), np.linalg.solve(np.dot(R, np.dot(self.cov_matrix, R.T)), R.T)))\n",
    "        dof = len(R)\n",
    "        p_value = 1 - f.cdf(wald_value, dfn=dof, dfd=len(self.left_hand_side) - len(self.beta))\n",
    "        return f\"Wald: {wald_value:.3f}, p-value: {p_value:.3f}\"\n",
    "\n",
    "    def get_model_goodness_values(self):\n",
    "        y_mean = np.mean(self.left_hand_side)\n",
    "        total_ss = np.sum((self.left_hand_side - y_mean) ** 2)\n",
    "        residual_ss = np.sum(self.residuals ** 2)\n",
    "        centered_r_squared = 1 - (residual_ss / total_ss)\n",
    "        n = len(self.left_hand_side)\n",
    "        k = len(self.beta)\n",
    "        adjusted_r_squared = 1 - ((1 - centered_r_squared) * (n - 1) / (n - k - 1))\n",
    "        return f\"Centered R-squared: {centered_r_squared:.3f}, Adjusted R-squared: {adjusted_r_squared:.3f}\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5137b6e2947a3ef8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
